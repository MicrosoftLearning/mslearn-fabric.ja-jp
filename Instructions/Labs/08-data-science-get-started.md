---
lab:
  title: Microsoft Fabric でデータ サイエンスを探索する
  module: Get started with data science in Microsoft Fabric
---

# Microsoft Fabric でデータ サイエンスを探索する

このラボでは、データの取り込み、ノートブック内でのデータの調査、Data Wrangler を使用したデータの処理、2 種類のモデルのトレーニングを行います。 これらのすべての手順を実行することで、Microsoft Fabric のデータ サイエンス機能を確認することができます。

このラボを完了することで、機械学習とモデル追跡に関するハンズオンの経験を積み、Microsoft Fabric で "ノートブック"、*Data Wrangler*、"実験"、"モデル" を操作する方法を学習できます。** ** **

このラボは完了するまで、約 **20** 分かかります。

> **注**:この演習を完了するには、Microsoft の"学校" または "職場" アカウントが必要です。**** お持ちでない場合は、[Microsoft Office 365 E3 以降の試用版にサインアップ](https://www.microsoft.com/microsoft-365/business/compare-more-office-365-for-business-plans)できます。

## ワークスペースの作成

Fabric でデータを操作する前に、Fabric 試用版を有効にしてワークスペースを作成してください。

1. ブラウザーで [https://app.fabric.microsoft.com](https://app.fabric.microsoft.com) の Microsoft Fabric ホーム ページに移動します。
1. **[Synapse Data Science]** を選択します。
1. 左側のメニュー バーで、 **[ワークスペース]** を選択します (アイコンは &#128455; に似ています)。
1. 任意の名前で新しいワークスペースを作成し、Fabric 容量を含むライセンス モード ("試用版"、*Premium*、または *Fabric*) を選択します。**
1. 開いた新しいワークスペースは空のはずです。

    ![Fabric の空のワークスペースを示すスクリーンショット。](./Images/new-workspace.png)

## ノートブックを作成する

コードを実行するには、"ノートブック" を作成します。** ノートブックは、(複数の言語で) コードを記述して実行できる対話型環境を提供します。

1. **Synapse Data Science** ホーム ページで、新しい**ノートブック**を作成します。

    数秒後に、1 つの ''セル'' を含む新しいノートブックが開きます。** ノートブックは、''コード'' または ''マークダウン'' (書式設定されたテキスト) を含むことができる 1 つまたは複数のセルで構成されます。** **

1. 最初のセル (現在は ''コード'' セル) を選択し、右上の動的ツール バーで **[M&#8595;]** ボタンを使用してセルを ''マークダウン'' セルに変換します。** **

    セルがマークダウン セルに変わると、それに含まれるテキストがレンダリングされます。

1. **[&#128393;]** (編集) ボタンを使用してセルを編集モードに切り替え、その内容を削除して次のテキストを入力します。

    ```text
   # Data science in Microsoft Fabric
    ```

## データを取得する

これで、データを取得してモデルをトレーニングするためのコードを実行する準備ができました。 Azure Open Datasets から [Diabetes データセット](https://learn.microsoft.com/azure/open-datasets/dataset-diabetes?tabs=azureml-opendatasets?azure-portal=true)を操作します。 データを読み込んだ後、データを Pandas データフレームに変換します。これは、行と列でデータを操作するための一般的な構造です。

1. ノートブックで、最新のセル出力の下にある **[+ コード]** アイコンを使用して、新しいコード セルをノートブックに追加します。

    > **ヒント**: **[+ コード]** アイコンを表示するには、マウスを現在のセルの出力のすぐ下かつ左に移動します。 別の方法として、メニュー バーの **[編集]** タブで、**[+ コード セルの追加]** を選択します。

1. 新しいコード セルに次のコードを入力します。

    ```python
   # Azure storage access info for open dataset diabetes
   blob_account_name = "azureopendatastorage"
   blob_container_name = "mlsamples"
   blob_relative_path = "diabetes"
   blob_sas_token = r"" # Blank since container is Anonymous access
    
   # Set Spark config to access  blob storage
   wasbs_path = f"wasbs://%s@%s.blob.core.windows.net/%s" % (blob_container_name, blob_account_name, blob_relative_path)
   spark.conf.set("fs.azure.sas.%s.%s.blob.core.windows.net" % (blob_container_name, blob_account_name), blob_sas_token)
   print("Remote blob path: " + wasbs_path)
    
   # Spark read parquet, note that it won't load any data yet by now
   df = spark.read.parquet(wasbs_path)
    ```

1. セルの左側にある **[&#9655;] (セルの実行)** ボタンを使用して実行します。 または、キーボードで `SHIFT` + `ENTER` キーを押してセルを実行できます。

    > **注**: このセッション内で Spark コードを実行したのはこれが最初であるため、Spark プールを起動する必要があります。 これは、セッション内での最初の実行が完了するまで 1 分ほどかかる場合があることを意味します。 それ以降は、短時間で実行できます。

1. セル出力の下にある **[+ コード]** アイコンを使用して、ノートブックに新しいコード セルを追加し、次のコードを入力します。

    ```python
   display(df)
    ```

1. セル コマンドが完了したら、セルの下にある出力を確認します。これは次のようになるはずです。

    |AGE|SEX|BMI|BP|S1|S2|S3|S4|S5|S6|Y|
    |---|---|---|--|--|--|--|--|--|--|--|
    |59|2|32.1|101.0|157|93.2|38.0|4.0|4.8598|87|151|
    |48|1|21.6|87.0|183|103.2|70.0|3.0|3.8918|69|75|
    |72|2|30.5|93.0|156|93.6|41.0|4.0|4.6728|85|141|
    |24|1|25.3|84.0|198|131.4|40.0|5.0|4.8903|89|206|
    |50|1|23.0|101.0|192|125.4|52.0|4.0|4.2905|80|135|
    | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |

    出力には、Diabetes データセットの行と列が表示されます。

1. レンダリングされたテーブルの上部には、**テーブル**と**グラフ**という 2 つのタブがあります。 **[グラフ]** を選択します。
1. グラフの右上にある **[表示オプション]** を選択して視覚化を変更します。
1. グラフを以下の設定に変更します。
    * **グラフの種類**: `Box plot`
    * **キー**: "空のままにします"**
    * **値**: `Y`
1. **[適用]** を選択して新しい視覚化をレンダリングし、出力を調べます。

## データを準備する

データの取り込みと調査が完了したので、データを変換できます。 ノートブックでコードを実行することも、Data Wrangler を使用してコードを生成することもできます。

1. データは Spark データフレームとして読み込まれます。 Data Wrangler を起動するには、データを Pandas データフレームに変換する必要があります。 ノートブックで次のコードを実行します。

    ```python
   df = df.toPandas()
   df.head()
    ```

1. ノートブック リボンの **[データ ]** を選択し、**[Data Wrangler の起動]** ドロップダウンを選択します。
1. `df` データセットを選択します。 Data Wrangler が起動すると、データフレームの説明的な概要が **[概要]** パネルに生成されます。

    現在、ラベル列は `Y` で、これは連続変数です。 Y を予測する機械学習モデルをトレーニングするには、回帰モデルをトレーニングする必要があります。 Y の (予測された) 値は解釈が困難な場合があります。 代わりに、ある人が糖尿病を発症するリスクが低いか高いかを予測する分類モデルのトレーニングを確認することができます。 分類モデルをトレーニングできるようにするには、`Y` の値に基づいてバイナリ ラベル列を作成する必要があります。

1. Data Wrangler で `Y` 列を選択します。 `220-240` ビンの頻度が低下している点に注意してください。 75 パーセンタイルの `211.5` は、ヒストグラム内の 2 つの領域の切り替わりとおおよそ一致しています。 この値を、低リスクと高リスクのしきい値として使用しましょう。
1. **[操作]** パネルに移動し、 **[数式]** を展開した後、 **[数式から列を作成]** を選択します。
1. 以下の設定で新しい列を作成します。
    * **列の名前**: `Risk`
    * **列の数式**: `(df['Y'] > 211.5).astype(int)`
1. プレビューに追加された新しい列 `Risk` を確認します。 値 `1` を持つ行の数が、すべての行の約 25% となっていることを確認します (これは `Y` の 75 パーセンタイルであるため)。
1. **適用**を選択します。
1. **[Add code to notebook] (ノートブックにコードを追加する)** を選択します。
1. Data Wrangler によって生成されたコードでセルを実行します。
1. 新しいセルで次のコードを実行して、`Risk` 列が期待どおりの形になっていることを確認します。

    ```python
   df_clean.describe()
    ```

## 機械学習モデルをトレーニングする

データの準備が完了したので、それを使用して機械学習モデルをトレーニングし、糖尿病の予測を行うことができます。 このデータセットを使用して、(`Y` を予測する) 回帰モデルまたは (`Risk` を予測する) 分類モデルという 2 種類の異なるモデルをトレーニングできます。 scikit-learn ライブラリを使用してモデルをトレーニングし、MLflow を使用してモデルを追跡します。

### 回帰モデルをトレーニングする

1. 次のコードを実行して、データをトレーニング データセットとテスト データセットに分割し、予測したいラベル `Y` から特徴量を分離します。

    ```python
   from sklearn.model_selection import train_test_split
    
   X, y = df_clean[['AGE','SEX','BMI','BP','S1','S2','S3','S4','S5','S6']].values, df_clean['Y'].values
    
   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)
    ```

1. ノートブックに新しいコード セルをもう 1 つ追加し、そこに次のコードを入力して実行します。

    ```python
   import mlflow
   experiment_name = "diabetes-regression"
   mlflow.set_experiment(experiment_name)
    ```

    このコードでは、`diabetes-regression` という名前の MLflow 実験を作成します。 この実験でモデルが追跡されます。

1. ノートブックに新しいコード セルをもう 1 つ追加し、そこに次のコードを入力して実行します。

    ```python
   from sklearn.linear_model import LinearRegression
    
   with mlflow.start_run():
      mlflow.autolog()
    
      model = LinearRegression()
      model.fit(X_train, y_train)
    ```

    このコードは、線形回帰を使用して回帰モデルをトレーニングします。 パラメーター、メトリック、および成果物は、MLflow で自動的にログに記録されます。

### 分類モデルをトレーニングする

1. 次のコードを実行して、データをトレーニング データセットとテスト データセットに分割し、予測したいラベル `Risk` から特徴量を分離します。

    ```python
   from sklearn.model_selection import train_test_split
    
   X, y = df_clean[['AGE','SEX','BMI','BP','S1','S2','S3','S4','S5','S6']].values, df_clean['Risk'].values
    
   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)
    ```

1. ノートブックに新しいコード セルをもう 1 つ追加し、そこに次のコードを入力して実行します。

    ```python
   import mlflow
   experiment_name = "diabetes-classification"
   mlflow.set_experiment(experiment_name)
    ```

    このコードでは、`diabetes-classification` という名前の MLflow 実験を作成します。 この実験でモデルが追跡されます。

1. ノートブックに新しいコード セルをもう 1 つ追加し、そこに次のコードを入力して実行します。

    ```python
   from sklearn.linear_model import LogisticRegression
    
   with mlflow.start_run():
       mlflow.sklearn.autolog()

       model = LogisticRegression(C=1/0.1, solver="liblinear").fit(X_train, y_train)
    ```

    このコードでは、ロジスティック回帰を使用して分類モデルをトレーニングします。 パラメーター、メトリック、および成果物は、MLflow で自動的にログに記録されます。

## 実験を調べる

Microsoft Fabric では、すべての実験を追跡し、それらを視覚的に調べることができます。

1. 左側のハブ メニュー バーからワークスペースに移動します。
1. `diabetes-regression` 実験を選択して開きます。

    > **ヒント:** ログに記録された実験の実行が表示されない場合は、ページを最新の情報に更新します。

1. **「メトリックの実行** を確認して、回帰モデルがどの程度正確であるかを調べます。
1. ホーム ページに戻り、`diabetes-classification` 実験を選択してこれを開きます。
1. **[メトリックの実行]** を確認して、分類モデルの正確性を調べます。 異なる種類のモデルをトレーニングしたため、メトリックの種類が異なることに注意してください。

## モデルを保存する

複数の実験にわたってトレーニングした機械学習モデルを比較した後、パフォーマンスが最も良いモデルを選択することができます。 最適なパフォーマンス モデルを使用するには、モデルを保存し、それを使用して予測を生成します。

1. **[モデルとして保存]** ボックスで **[保存]** を選択します。
1. 新しく開いたポップアップ ウィンドウで **[新しいモデルの作成]** を選択します。
1. `model` フォルダーを選択します。
1. モデルに `model-diabetes` という名前を付け、 **[保存]** を選択します。
1. モデルの作成時に画面の右上に表示される通知で、 **[モデルの表示]** を選択します。 ウィンドウを最新の情報に更新することもできます。 保存されたモデルは、 **[モデル バージョン]** の下にリンクされています。

モデル、実験、実験の実行がリンクされていることに注意してください。これにより、モデルのトレーニング方法を確認できます。

## ノートブックを保存して Spark セッションを終了する

モデルのトレーニングと評価が完了したので、わかりやすい名前でノートブックを保存し、Spark セッションを終了できます。

1. ノートブックのメニュー バーで、[⚙️] (**設定**) アイコンを使用してノートブックの設定を表示します。
2. ノートブックの **[名前]** を **[モデルのトレーニングと比較]** に設定し、設定ペインを閉じます。
3. ノートブック メニューで、 **[セッションの停止]** を選択して Spark セッションを終了します。

## リソースをクリーンアップする

この演習では、ノートブックを作成し、機械学習モデルをトレーニングしました。 scikit-learn を使用してモデルをトレーニングし、MLflow でそのパフォーマンスを追跡しました。

モデルと実験の確認が完了したら、この演習用に作成したワークスペースを削除して構いません。

1. 左側のバーで、ワークスペースのアイコンを選択して、それに含まれるすべての項目を表示します。
2. ツール バーの **[...]** メニューで、 **[ワークスペースの設定]** を選択します。
3. **[その他]** セクションで、 **[このワークスペースの削除]** を選択してください。
